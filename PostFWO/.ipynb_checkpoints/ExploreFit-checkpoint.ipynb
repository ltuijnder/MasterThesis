{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Auto reloading moduls\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from helpFunctions import *\n",
    "from generateGLV import *\n",
    "from fitGLV import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will run a long loop. -> Hence we want to ignore all warnigns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExploreFit\n",
    "In this notebook we will explore the different conditions on how good one can fit. For this we generate many timeseries for one condition and then compute the summarising value for those. Based on those many result we then make plots from which we draw our conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is pretty impossible to store everything in RAM, since this will be huge -> We will compute setting per setting and only save the most important from the generated timeseries. \n",
    "\n",
    "What we will do is just store the X,Y of each setting generated. -> Such that latter, if needed, one can again start from computing those.\n",
    "Ok after calculating. For a simple grid -> Computing all data and storing all X, Y values would cost intotal 13 GB of space... We have that but it is not worth it + that would also take an insane amount of time. So we skip the saving of the data. What we do can do however is store the real matrix, the fitted matrix and the variance. \n",
    "\n",
    "We do accumalate our results from the different settings and also store those. Such that it does not need to be computed afterwards. (but this could be done really quick (normally))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the setting grid over which we want to loop.\n",
    "noiseStrength = np.array([0.00001,0.0001,0.001,0.01,0.05,0.1,1])\n",
    "noiseLen = len(noiseStrength)\n",
    "interStength = np.array([0.,0.01,0.05,0.1,0.5,1,1.5])\n",
    "interLen = len(interStength)\n",
    "pertu = np.array([1000,50,20,10,5,1])\n",
    "pertuLen = len(pertu)\n",
    "shape = (pertuLen,noiseLen,interLen)\n",
    "# 7*7*6 = 294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "noiseSetting = {\n",
    "    \"noiseType\" : \"LangevinLinear\",\n",
    "    \"noiseStrength\" : 0.02\n",
    "}\n",
    "pertuSetting = {\n",
    "    \"period\" : 1000,\n",
    "    \"strenght\" : 0.05\n",
    "}\n",
    "genSetting = {\n",
    "    \"interactionStrenght\" : 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Big for loop that will loop over everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberSpecies = 5\n",
    "numberExperiments = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each setting we want to summarise to summarise the setting. We have 12 summarising values. That we want to store. For that we each need to compute mean and std. And also store that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(MEANpercentG,MEANpercentS,MEANpercentI,MEANpercentWAvg) = (np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf))\n",
    "(STDpercentG,STDpercentS,STDpercentI,STDpercentWAvg) = (np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf))\n",
    "(MEANmedianG,MEANmedianS,MEANmedianI,MEANmedianWAvg) = (np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf))\n",
    "(STDmedianG,STDmedianS,STDmedianI,STDmedianWAvg) = (np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf))\n",
    "(MEANavgG,MEANavgS,MEANavgI,MEANavgWAvg) = (np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf))\n",
    "(STDavgG,STDavgS,STDavgI,STDavgWAvg) = (np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf),np.full(shape,np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important settings of series 1\n",
    "\n",
    "- Settings are: \n",
    "    - Noise = np.array([0.00001,0.0001,0.001,0.01,0.05,0.1,1])\n",
    "    - InteractionStrength np.array([0.,0.01,0.05,0.1,0.5,1,1.5])\n",
    "    - Pertu = np.array([1000,50,20,10,5,1])\n",
    "    - Order (i,j,k) = (pertu,Noise,Inter)\n",
    "- NoiseType = \"LangevinLinear\n",
    "- PertuStrenght = 0.05\n",
    "- Pertubation type Random\n",
    "- Timestep = 0.01\n",
    "- Intergration Type = euler\n",
    "- SteadyState = all 1\n",
    "- numberspecies = 5\n",
    "- number of Exp = 50\n",
    "- selfInteraction = uniform(-1.9,-0.1)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started p=1000\n",
      "Started n=1e-05\n",
      "Started s=0.0, count=0/294, left = 294, Time last loop = 0.0 seconds\n",
      "Started s=0.01, count=1/294, left = 293, Time last loop = 48.07 seconds\n",
      "Started s=0.05, count=2/294, left = 292, Time last loop = 45.62 seconds\n",
      "Started s=0.1, count=3/294, left = 291, Time last loop = 46.99 seconds\n",
      "Started s=0.5, count=4/294, left = 290, Time last loop = 45.13 seconds\n",
      "Started s=1.0, count=5/294, left = 289, Time last loop = 45.51 seconds\n",
      "Started s=1.5, count=6/294, left = 288, Time last loop = 40.63 seconds\n",
      "Started n=0.0001\n",
      "Started s=0.0, count=7/294, left = 287, Time last loop = 40.9 seconds\n",
      "Started s=0.01, count=8/294, left = 286, Time last loop = 42.15 seconds\n",
      "Started s=0.05, count=9/294, left = 285, Time last loop = 43.39 seconds\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "date = time.time() # First empty\n",
    "for i, p in enumerate(pertu):\n",
    "    print(f\"Started p={p}\")\n",
    "    pertuSetting[\"period\"] = p\n",
    "    for j, n in enumerate(noiseStrength):\n",
    "        print(f\"Started n={n}\")\n",
    "        noiseSetting[\"noiseStrength\"] = n\n",
    "        for k, s in enumerate(interStength):\n",
    "            print(f\"Started s={s}, count={count}/294, left = {294-count}, Time last loop = {np.round(time.time()-date,2)} seconds\")\n",
    "            date = time.time()\n",
    "            genSetting[\"interactionStrenght\"] = s\n",
    "            count += 1\n",
    "            \n",
    "            TS =  TS_GLV(numberSpecies,numberExperiments,noiseSetting,genSetting,pertuSetting)\n",
    "            TS.generate()\n",
    "            fitObj = fitGLV(TS)\n",
    "            fitObj.computeNullHypo()\n",
    "            \n",
    "            # Store the important matrixes\n",
    "            np.save(f\"DataStorage/Series1/trueMat{i}{j}{k}.npy\",fitObj.trueMat)\n",
    "            np.save(f\"DataStorage/Series1/BEst{i}{j}{k}.npy\",fitObj.BEst)\n",
    "            np.save(f\"DataStorage/Series1/varBEst{i}{j}{k}.npy\",fitObj.varBEst)\n",
    "            \n",
    "            # Store the wanted values in seperate matrixes\n",
    "            saveAndStoreSummary((i,j,k),fitObj.nullSummary,\"DataStorage/Series1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveAndStoreSummary(c,S,p):\n",
    "    # c = coordinates, S = summary, p=path\n",
    "    # First update all the data matrixes\n",
    "    percentArray = np.array([S[\"percentG\"],S[\"percentS\"],S[\"percentI\"],S[\"percentWAvg\"]])\n",
    "    (MEANpercentG[c],MEANpercentS[c],MEANpercentI[c],MEANpercentWAvg[c]) = np.mean(percentArray,axis=1)\n",
    "    (STDpercentG[c],STDpercentS[c],STDpercentI[c],STDpercentWAvg[c]) = np.std(percentArray,axis=1)\n",
    "    \n",
    "    medianArray = np.array([S[\"medianG\"],S[\"medianS\"],S[\"medianI\"],S[\"medianWAvg\"]])\n",
    "    (MEANmedianG[c],MEANmedianS[c],MEANmedianI[c],MEANmedianWAvg[c]) = np.mean(medianArray,axis=1)\n",
    "    (STDmedianG[c],STDmedianS[c],STDmedianI[c],STDmedianWAvg[c]) = np.std(medianArray,axis=1)\n",
    "    \n",
    "    avgArray = np.array([S[\"avgG\"],S[\"avgS\"],S[\"avgI\"],S[\"avgWAvg\"]])\n",
    "    (MEANavgG[c],MEANavgS[c],MEANavgI[c],MEANavgWAvg[c]) = np.mean(avgArray,axis=1)\n",
    "    (STDavgG[c],STDavgS[c],STDavgI[c],STDavgWAvg[c]) = np.std(avgArray,axis=1)\n",
    "    \n",
    "    # Now for safty if something would go wrong during generation we save at each stept the matrices!\n",
    "    np.save(p+\"MEANpercentG.npy\",MEANpercentG)\n",
    "    np.save(p+\"MEANpercentS.npy\",MEANpercentS)\n",
    "    np.save(p+\"MEANpercentI.npy\",MEANpercentI)\n",
    "    np.save(p+\"MEANpercentWavg.npy\",MEANpercentWAvg)\n",
    "    np.save(p+\"STDpercentG.npy\",STDpercentG)\n",
    "    np.save(p+\"STDpercentS.npy\",STDpercentS)\n",
    "    np.save(p+\"STDpercentI.npy\",STDpercentI)\n",
    "    np.save(p+\"STDpercentWAvg.npy\",STDpercentWAvg)\n",
    "    \n",
    "    np.save(p+\"MEANmedianG.npy\",MEANmedianG)\n",
    "    np.save(p+\"MEANmedianS.npy\",MEANmedianS)\n",
    "    np.save(p+\"MEANmedianI.npy\",MEANmedianI)\n",
    "    np.save(p+\"MEANmedianWAvg.npy\",MEANmedianWAvg)\n",
    "    np.save(p+\"STDmedianG.npy\",STDmedianG)\n",
    "    np.save(p+\"STDmedianS.npy\",STDmedianS)\n",
    "    np.save(p+\"STDmedianI.npy\",STDmedianI)\n",
    "    np.save(p+\"STDmedianWAvg.npy\",STDmedianWAvg)\n",
    "    \n",
    "    np.save(p+\"MEANavgG.npy\",MEANavgG)\n",
    "    np.save(p+\"MEANavgS.npy\",MEANavgS)\n",
    "    np.save(p+\"MEANavgI.npy\",MEANavgI)\n",
    "    np.save(p+\"MEANavgWAvg.npy\",MEANavgWAvg)\n",
    "    np.save(p+\"STDavgG.npy\",STDavgG)\n",
    "    np.save(p+\"STDavgS.npy\",STDavgS)\n",
    "    np.save(p+\"STDavgI.npy\",STDavgI)\n",
    "    np.save(p+\"STDavgWAvg.npy\",STDavgWAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
